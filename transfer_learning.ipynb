{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "transfer learning with keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## encoding=utf-8\n",
    "# 从某一层开始获取权重并开始transferlearning\n",
    "# 输入图像的大小建议和pre_process model要求的输入大小一致，效果会更好\n",
    "# 从处理方式的灵活性上推荐函数式模型，sequential只是特例\n",
    "# 各层的激活函数优先选sigmoid ，即便是最后一层的softmax?\n",
    "# 将最后一层的输出作为输入的ＴＬ实验３ 起始准确率不到２０　而本实验直接将池化层的结果作为输入　然后ｓｏｆｔｍａｘｘ获得的起始准确率达６０％\n",
    "\n",
    "#总结一下：　ｔransfer learning :利用现有的模型，将特征层剥离，然后fine-truning\n",
    "# １可以直接将输出层作为输入\n",
    "# ２将中间某层（最好是特征层，比如卷积后，ＦＣ已经到达了抽象的感知事物的理解程度）或多层（trainable）\n",
    "# 另外，还有就是自己写将多次结果的数据写到ｈ５文件中，然后读取\n",
    "\n",
    "# keras 2.1.5\n",
    "# 报错：StopIteration: unsupported operand type(s) for /=: 'JpegImageFile' and 'float'\n",
    "# 降级到2.1.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.applications import *\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "#释放显存\n",
    "os.system(\"nvidia-smi | grep vpython3 | awk '{print $3}' | xargs kill -9\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "height=224\n",
    "train_batch_size=64\n",
    "test_batch_size=64\n",
    "FLAG = None\n",
    "#assert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4170 images belonging to 3 classes.\n",
      "Found 530 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "train_data_dir='/home/naruto/PycharmProjects/knifey_spoony_demo/data/knifey-spoony/train_data_link/'\n",
    "test_data_dir='/home/naruto/PycharmProjects/knifey_spoony_demo/data/knifey-spoony/test/'\n",
    "gen = ImageDataGenerator()\n",
    "generator_train = gen.flow_from_directory(train_data_dir, target_size=(height, height),batch_size=train_batch_size)\n",
    "generator_test = gen.flow_from_directory(test_data_dir, target_size=(height, height),batch_size=test_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_1 (InputLayer)             (None, 224, 224, 3)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "zero_padding2d_1 (ZeroPadding2D) (None, 230, 230, 3)   0           input_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                   (None, 112, 112, 64)  9472        zero_padding2d_1[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "bn_conv1 (BatchNormalization)    (None, 112, 112, 64)  256         conv1[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "activation_1 (Activation)        (None, 112, 112, 64)  0           bn_conv1[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)   (None, 55, 55, 64)    0           activation_1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "res2a_branch2a (Conv2D)          (None, 55, 55, 64)    4160        max_pooling2d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "bn2a_branch2a (BatchNormalizatio (None, 55, 55, 64)    256         res2a_branch2a[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_2 (Activation)        (None, 55, 55, 64)    0           bn2a_branch2a[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res2a_branch2b (Conv2D)          (None, 55, 55, 64)    36928       activation_2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "bn2a_branch2b (BatchNormalizatio (None, 55, 55, 64)    256         res2a_branch2b[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_3 (Activation)        (None, 55, 55, 64)    0           bn2a_branch2b[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res2a_branch2c (Conv2D)          (None, 55, 55, 256)   16640       activation_3[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "res2a_branch1 (Conv2D)           (None, 55, 55, 256)   16640       max_pooling2d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "bn2a_branch2c (BatchNormalizatio (None, 55, 55, 256)   1024        res2a_branch2c[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "bn2a_branch1 (BatchNormalization (None, 55, 55, 256)   1024        res2a_branch1[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "add_1 (Add)                      (None, 55, 55, 256)   0           bn2a_branch2c[0][0]              \n",
      "                                                                   bn2a_branch1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "activation_4 (Activation)        (None, 55, 55, 256)   0           add_1[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "res2b_branch2a (Conv2D)          (None, 55, 55, 64)    16448       activation_4[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "bn2b_branch2a (BatchNormalizatio (None, 55, 55, 64)    256         res2b_branch2a[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_5 (Activation)        (None, 55, 55, 64)    0           bn2b_branch2a[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res2b_branch2b (Conv2D)          (None, 55, 55, 64)    36928       activation_5[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "bn2b_branch2b (BatchNormalizatio (None, 55, 55, 64)    256         res2b_branch2b[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_6 (Activation)        (None, 55, 55, 64)    0           bn2b_branch2b[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res2b_branch2c (Conv2D)          (None, 55, 55, 256)   16640       activation_6[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "bn2b_branch2c (BatchNormalizatio (None, 55, 55, 256)   1024        res2b_branch2c[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "add_2 (Add)                      (None, 55, 55, 256)   0           bn2b_branch2c[0][0]              \n",
      "                                                                   activation_4[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "activation_7 (Activation)        (None, 55, 55, 256)   0           add_2[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "res2c_branch2a (Conv2D)          (None, 55, 55, 64)    16448       activation_7[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "bn2c_branch2a (BatchNormalizatio (None, 55, 55, 64)    256         res2c_branch2a[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_8 (Activation)        (None, 55, 55, 64)    0           bn2c_branch2a[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res2c_branch2b (Conv2D)          (None, 55, 55, 64)    36928       activation_8[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "bn2c_branch2b (BatchNormalizatio (None, 55, 55, 64)    256         res2c_branch2b[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_9 (Activation)        (None, 55, 55, 64)    0           bn2c_branch2b[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res2c_branch2c (Conv2D)          (None, 55, 55, 256)   16640       activation_9[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "bn2c_branch2c (BatchNormalizatio (None, 55, 55, 256)   1024        res2c_branch2c[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "add_3 (Add)                      (None, 55, 55, 256)   0           bn2c_branch2c[0][0]              \n",
      "                                                                   activation_7[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "activation_10 (Activation)       (None, 55, 55, 256)   0           add_3[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "res3a_branch2a (Conv2D)          (None, 28, 28, 128)   32896       activation_10[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn3a_branch2a (BatchNormalizatio (None, 28, 28, 128)   512         res3a_branch2a[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_11 (Activation)       (None, 28, 28, 128)   0           bn3a_branch2a[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res3a_branch2b (Conv2D)          (None, 28, 28, 128)   147584      activation_11[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn3a_branch2b (BatchNormalizatio (None, 28, 28, 128)   512         res3a_branch2b[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_12 (Activation)       (None, 28, 28, 128)   0           bn3a_branch2b[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res3a_branch2c (Conv2D)          (None, 28, 28, 512)   66048       activation_12[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res3a_branch1 (Conv2D)           (None, 28, 28, 512)   131584      activation_10[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn3a_branch2c (BatchNormalizatio (None, 28, 28, 512)   2048        res3a_branch2c[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "bn3a_branch1 (BatchNormalization (None, 28, 28, 512)   2048        res3a_branch1[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "add_4 (Add)                      (None, 28, 28, 512)   0           bn3a_branch2c[0][0]              \n",
      "                                                                   bn3a_branch1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "activation_13 (Activation)       (None, 28, 28, 512)   0           add_4[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "res3b_branch2a (Conv2D)          (None, 28, 28, 128)   65664       activation_13[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn3b_branch2a (BatchNormalizatio (None, 28, 28, 128)   512         res3b_branch2a[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_14 (Activation)       (None, 28, 28, 128)   0           bn3b_branch2a[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res3b_branch2b (Conv2D)          (None, 28, 28, 128)   147584      activation_14[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn3b_branch2b (BatchNormalizatio (None, 28, 28, 128)   512         res3b_branch2b[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_15 (Activation)       (None, 28, 28, 128)   0           bn3b_branch2b[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res3b_branch2c (Conv2D)          (None, 28, 28, 512)   66048       activation_15[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn3b_branch2c (BatchNormalizatio (None, 28, 28, 512)   2048        res3b_branch2c[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "add_5 (Add)                      (None, 28, 28, 512)   0           bn3b_branch2c[0][0]              \n",
      "                                                                   activation_13[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_16 (Activation)       (None, 28, 28, 512)   0           add_5[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "res3c_branch2a (Conv2D)          (None, 28, 28, 128)   65664       activation_16[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn3c_branch2a (BatchNormalizatio (None, 28, 28, 128)   512         res3c_branch2a[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_17 (Activation)       (None, 28, 28, 128)   0           bn3c_branch2a[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res3c_branch2b (Conv2D)          (None, 28, 28, 128)   147584      activation_17[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn3c_branch2b (BatchNormalizatio (None, 28, 28, 128)   512         res3c_branch2b[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_18 (Activation)       (None, 28, 28, 128)   0           bn3c_branch2b[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res3c_branch2c (Conv2D)          (None, 28, 28, 512)   66048       activation_18[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn3c_branch2c (BatchNormalizatio (None, 28, 28, 512)   2048        res3c_branch2c[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "add_6 (Add)                      (None, 28, 28, 512)   0           bn3c_branch2c[0][0]              \n",
      "                                                                   activation_16[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_19 (Activation)       (None, 28, 28, 512)   0           add_6[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "res3d_branch2a (Conv2D)          (None, 28, 28, 128)   65664       activation_19[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn3d_branch2a (BatchNormalizatio (None, 28, 28, 128)   512         res3d_branch2a[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_20 (Activation)       (None, 28, 28, 128)   0           bn3d_branch2a[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res3d_branch2b (Conv2D)          (None, 28, 28, 128)   147584      activation_20[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn3d_branch2b (BatchNormalizatio (None, 28, 28, 128)   512         res3d_branch2b[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_21 (Activation)       (None, 28, 28, 128)   0           bn3d_branch2b[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res3d_branch2c (Conv2D)          (None, 28, 28, 512)   66048       activation_21[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn3d_branch2c (BatchNormalizatio (None, 28, 28, 512)   2048        res3d_branch2c[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "add_7 (Add)                      (None, 28, 28, 512)   0           bn3d_branch2c[0][0]              \n",
      "                                                                   activation_19[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_22 (Activation)       (None, 28, 28, 512)   0           add_7[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "res4a_branch2a (Conv2D)          (None, 14, 14, 256)   131328      activation_22[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn4a_branch2a (BatchNormalizatio (None, 14, 14, 256)   1024        res4a_branch2a[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_23 (Activation)       (None, 14, 14, 256)   0           bn4a_branch2a[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res4a_branch2b (Conv2D)          (None, 14, 14, 256)   590080      activation_23[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn4a_branch2b (BatchNormalizatio (None, 14, 14, 256)   1024        res4a_branch2b[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_24 (Activation)       (None, 14, 14, 256)   0           bn4a_branch2b[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res4a_branch2c (Conv2D)          (None, 14, 14, 1024)  263168      activation_24[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res4a_branch1 (Conv2D)           (None, 14, 14, 1024)  525312      activation_22[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn4a_branch2c (BatchNormalizatio (None, 14, 14, 1024)  4096        res4a_branch2c[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "bn4a_branch1 (BatchNormalization (None, 14, 14, 1024)  4096        res4a_branch1[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "add_8 (Add)                      (None, 14, 14, 1024)  0           bn4a_branch2c[0][0]              \n",
      "                                                                   bn4a_branch1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "activation_25 (Activation)       (None, 14, 14, 1024)  0           add_8[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "res4b_branch2a (Conv2D)          (None, 14, 14, 256)   262400      activation_25[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn4b_branch2a (BatchNormalizatio (None, 14, 14, 256)   1024        res4b_branch2a[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_26 (Activation)       (None, 14, 14, 256)   0           bn4b_branch2a[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res4b_branch2b (Conv2D)          (None, 14, 14, 256)   590080      activation_26[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn4b_branch2b (BatchNormalizatio (None, 14, 14, 256)   1024        res4b_branch2b[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_27 (Activation)       (None, 14, 14, 256)   0           bn4b_branch2b[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res4b_branch2c (Conv2D)          (None, 14, 14, 1024)  263168      activation_27[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn4b_branch2c (BatchNormalizatio (None, 14, 14, 1024)  4096        res4b_branch2c[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "add_9 (Add)                      (None, 14, 14, 1024)  0           bn4b_branch2c[0][0]              \n",
      "                                                                   activation_25[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_28 (Activation)       (None, 14, 14, 1024)  0           add_9[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "res4c_branch2a (Conv2D)          (None, 14, 14, 256)   262400      activation_28[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn4c_branch2a (BatchNormalizatio (None, 14, 14, 256)   1024        res4c_branch2a[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_29 (Activation)       (None, 14, 14, 256)   0           bn4c_branch2a[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res4c_branch2b (Conv2D)          (None, 14, 14, 256)   590080      activation_29[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn4c_branch2b (BatchNormalizatio (None, 14, 14, 256)   1024        res4c_branch2b[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_30 (Activation)       (None, 14, 14, 256)   0           bn4c_branch2b[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res4c_branch2c (Conv2D)          (None, 14, 14, 1024)  263168      activation_30[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn4c_branch2c (BatchNormalizatio (None, 14, 14, 1024)  4096        res4c_branch2c[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "add_10 (Add)                     (None, 14, 14, 1024)  0           bn4c_branch2c[0][0]              \n",
      "                                                                   activation_28[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_31 (Activation)       (None, 14, 14, 1024)  0           add_10[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "res4d_branch2a (Conv2D)          (None, 14, 14, 256)   262400      activation_31[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn4d_branch2a (BatchNormalizatio (None, 14, 14, 256)   1024        res4d_branch2a[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_32 (Activation)       (None, 14, 14, 256)   0           bn4d_branch2a[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res4d_branch2b (Conv2D)          (None, 14, 14, 256)   590080      activation_32[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn4d_branch2b (BatchNormalizatio (None, 14, 14, 256)   1024        res4d_branch2b[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_33 (Activation)       (None, 14, 14, 256)   0           bn4d_branch2b[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res4d_branch2c (Conv2D)          (None, 14, 14, 1024)  263168      activation_33[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn4d_branch2c (BatchNormalizatio (None, 14, 14, 1024)  4096        res4d_branch2c[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "add_11 (Add)                     (None, 14, 14, 1024)  0           bn4d_branch2c[0][0]              \n",
      "                                                                   activation_31[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_34 (Activation)       (None, 14, 14, 1024)  0           add_11[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "res4e_branch2a (Conv2D)          (None, 14, 14, 256)   262400      activation_34[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn4e_branch2a (BatchNormalizatio (None, 14, 14, 256)   1024        res4e_branch2a[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_35 (Activation)       (None, 14, 14, 256)   0           bn4e_branch2a[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res4e_branch2b (Conv2D)          (None, 14, 14, 256)   590080      activation_35[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn4e_branch2b (BatchNormalizatio (None, 14, 14, 256)   1024        res4e_branch2b[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_36 (Activation)       (None, 14, 14, 256)   0           bn4e_branch2b[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res4e_branch2c (Conv2D)          (None, 14, 14, 1024)  263168      activation_36[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn4e_branch2c (BatchNormalizatio (None, 14, 14, 1024)  4096        res4e_branch2c[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "add_12 (Add)                     (None, 14, 14, 1024)  0           bn4e_branch2c[0][0]              \n",
      "                                                                   activation_34[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_37 (Activation)       (None, 14, 14, 1024)  0           add_12[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "res4f_branch2a (Conv2D)          (None, 14, 14, 256)   262400      activation_37[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn4f_branch2a (BatchNormalizatio (None, 14, 14, 256)   1024        res4f_branch2a[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_38 (Activation)       (None, 14, 14, 256)   0           bn4f_branch2a[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res4f_branch2b (Conv2D)          (None, 14, 14, 256)   590080      activation_38[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn4f_branch2b (BatchNormalizatio (None, 14, 14, 256)   1024        res4f_branch2b[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_39 (Activation)       (None, 14, 14, 256)   0           bn4f_branch2b[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res4f_branch2c (Conv2D)          (None, 14, 14, 1024)  263168      activation_39[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn4f_branch2c (BatchNormalizatio (None, 14, 14, 1024)  4096        res4f_branch2c[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "add_13 (Add)                     (None, 14, 14, 1024)  0           bn4f_branch2c[0][0]              \n",
      "                                                                   activation_37[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_40 (Activation)       (None, 14, 14, 1024)  0           add_13[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "res5a_branch2a (Conv2D)          (None, 7, 7, 512)     524800      activation_40[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn5a_branch2a (BatchNormalizatio (None, 7, 7, 512)     2048        res5a_branch2a[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_41 (Activation)       (None, 7, 7, 512)     0           bn5a_branch2a[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res5a_branch2b (Conv2D)          (None, 7, 7, 512)     2359808     activation_41[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn5a_branch2b (BatchNormalizatio (None, 7, 7, 512)     2048        res5a_branch2b[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_42 (Activation)       (None, 7, 7, 512)     0           bn5a_branch2b[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res5a_branch2c (Conv2D)          (None, 7, 7, 2048)    1050624     activation_42[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res5a_branch1 (Conv2D)           (None, 7, 7, 2048)    2099200     activation_40[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn5a_branch2c (BatchNormalizatio (None, 7, 7, 2048)    8192        res5a_branch2c[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "bn5a_branch1 (BatchNormalization (None, 7, 7, 2048)    8192        res5a_branch1[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "add_14 (Add)                     (None, 7, 7, 2048)    0           bn5a_branch2c[0][0]              \n",
      "                                                                   bn5a_branch1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "activation_43 (Activation)       (None, 7, 7, 2048)    0           add_14[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "res5b_branch2a (Conv2D)          (None, 7, 7, 512)     1049088     activation_43[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn5b_branch2a (BatchNormalizatio (None, 7, 7, 512)     2048        res5b_branch2a[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_44 (Activation)       (None, 7, 7, 512)     0           bn5b_branch2a[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res5b_branch2b (Conv2D)          (None, 7, 7, 512)     2359808     activation_44[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn5b_branch2b (BatchNormalizatio (None, 7, 7, 512)     2048        res5b_branch2b[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_45 (Activation)       (None, 7, 7, 512)     0           bn5b_branch2b[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res5b_branch2c (Conv2D)          (None, 7, 7, 2048)    1050624     activation_45[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn5b_branch2c (BatchNormalizatio (None, 7, 7, 2048)    8192        res5b_branch2c[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "add_15 (Add)                     (None, 7, 7, 2048)    0           bn5b_branch2c[0][0]              \n",
      "                                                                   activation_43[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_46 (Activation)       (None, 7, 7, 2048)    0           add_15[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "res5c_branch2a (Conv2D)          (None, 7, 7, 512)     1049088     activation_46[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn5c_branch2a (BatchNormalizatio (None, 7, 7, 512)     2048        res5c_branch2a[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_47 (Activation)       (None, 7, 7, 512)     0           bn5c_branch2a[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res5c_branch2b (Conv2D)          (None, 7, 7, 512)     2359808     activation_47[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn5c_branch2b (BatchNormalizatio (None, 7, 7, 512)     2048        res5c_branch2b[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_48 (Activation)       (None, 7, 7, 512)     0           bn5c_branch2b[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "res5c_branch2c (Conv2D)          (None, 7, 7, 2048)    1050624     activation_48[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bn5c_branch2c (BatchNormalizatio (None, 7, 7, 2048)    8192        res5c_branch2c[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "add_16 (Add)                     (None, 7, 7, 2048)    0           bn5c_branch2c[0][0]              \n",
      "                                                                   activation_46[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_49 (Activation)       (None, 7, 7, 2048)    0           add_16[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "avg_pool (AveragePooling2D)      (None, 1, 1, 2048)    0           activation_49[0][0]              \n",
      "====================================================================================================\n",
      "Total params: 23,587,712\n",
      "Trainable params: 23,534,592\n",
      "Non-trainable params: 53,120\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# base_model = VGG16(include_top=True, weights='imagenet')需要下载，速度慢，\n",
    "# include_top=true时下载也比较慢，需要测试等于true时的模型结构\n",
    "# input_tensor=Input((height, height, 3))报错ValueError: The shape of the input to \"Flatten\" is not fully defined (got (None, None, 2048).\n",
    "#  Make sure to pass a complete \"input_shape\" or \"batch_input_shape\" argument to the first layer in your model.，是因为此时用的Ｍｏｄｅｌ需要预先指定ｉｎｐｕｔ\n",
    "base_model = ResNet50(input_tensor=Input((height, height, 3)),weights='imagenet', include_top=False)\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer_0:\tFalse\tinput_1\n",
      "layer_1:\tTrue\tzero_padding2d_1\n",
      "layer_2:\tTrue\tconv1\n",
      "layer_3:\tTrue\tbn_conv1\n",
      "layer_4:\tTrue\tactivation_1\n",
      "layer_5:\tTrue\tmax_pooling2d_1\n",
      "layer_6:\tTrue\tres2a_branch2a\n",
      "layer_7:\tTrue\tbn2a_branch2a\n",
      "layer_8:\tTrue\tactivation_2\n",
      "layer_9:\tTrue\tres2a_branch2b\n",
      "layer_10:\tTrue\tbn2a_branch2b\n",
      "layer_11:\tTrue\tactivation_3\n",
      "layer_12:\tTrue\tres2a_branch2c\n",
      "layer_13:\tTrue\tres2a_branch1\n",
      "layer_14:\tTrue\tbn2a_branch2c\n",
      "layer_15:\tTrue\tbn2a_branch1\n",
      "layer_16:\tTrue\tadd_1\n",
      "layer_17:\tTrue\tactivation_4\n",
      "layer_18:\tTrue\tres2b_branch2a\n",
      "layer_19:\tTrue\tbn2b_branch2a\n",
      "layer_20:\tTrue\tactivation_5\n",
      "layer_21:\tTrue\tres2b_branch2b\n",
      "layer_22:\tTrue\tbn2b_branch2b\n",
      "layer_23:\tTrue\tactivation_6\n",
      "layer_24:\tTrue\tres2b_branch2c\n",
      "layer_25:\tTrue\tbn2b_branch2c\n",
      "layer_26:\tTrue\tadd_2\n",
      "layer_27:\tTrue\tactivation_7\n",
      "layer_28:\tTrue\tres2c_branch2a\n",
      "layer_29:\tTrue\tbn2c_branch2a\n",
      "layer_30:\tTrue\tactivation_8\n",
      "layer_31:\tTrue\tres2c_branch2b\n",
      "layer_32:\tTrue\tbn2c_branch2b\n",
      "layer_33:\tTrue\tactivation_9\n",
      "layer_34:\tTrue\tres2c_branch2c\n",
      "layer_35:\tTrue\tbn2c_branch2c\n",
      "layer_36:\tTrue\tadd_3\n",
      "layer_37:\tTrue\tactivation_10\n",
      "layer_38:\tTrue\tres3a_branch2a\n",
      "layer_39:\tTrue\tbn3a_branch2a\n",
      "layer_40:\tTrue\tactivation_11\n",
      "layer_41:\tTrue\tres3a_branch2b\n",
      "layer_42:\tTrue\tbn3a_branch2b\n",
      "layer_43:\tTrue\tactivation_12\n",
      "layer_44:\tTrue\tres3a_branch2c\n",
      "layer_45:\tTrue\tres3a_branch1\n",
      "layer_46:\tTrue\tbn3a_branch2c\n",
      "layer_47:\tTrue\tbn3a_branch1\n",
      "layer_48:\tTrue\tadd_4\n",
      "layer_49:\tTrue\tactivation_13\n",
      "layer_50:\tTrue\tres3b_branch2a\n",
      "layer_51:\tTrue\tbn3b_branch2a\n",
      "layer_52:\tTrue\tactivation_14\n",
      "layer_53:\tTrue\tres3b_branch2b\n",
      "layer_54:\tTrue\tbn3b_branch2b\n",
      "layer_55:\tTrue\tactivation_15\n",
      "layer_56:\tTrue\tres3b_branch2c\n",
      "layer_57:\tTrue\tbn3b_branch2c\n",
      "layer_58:\tTrue\tadd_5\n",
      "layer_59:\tTrue\tactivation_16\n",
      "layer_60:\tTrue\tres3c_branch2a\n",
      "layer_61:\tTrue\tbn3c_branch2a\n",
      "layer_62:\tTrue\tactivation_17\n",
      "layer_63:\tTrue\tres3c_branch2b\n",
      "layer_64:\tTrue\tbn3c_branch2b\n",
      "layer_65:\tTrue\tactivation_18\n",
      "layer_66:\tTrue\tres3c_branch2c\n",
      "layer_67:\tTrue\tbn3c_branch2c\n",
      "layer_68:\tTrue\tadd_6\n",
      "layer_69:\tTrue\tactivation_19\n",
      "layer_70:\tTrue\tres3d_branch2a\n",
      "layer_71:\tTrue\tbn3d_branch2a\n",
      "layer_72:\tTrue\tactivation_20\n",
      "layer_73:\tTrue\tres3d_branch2b\n",
      "layer_74:\tTrue\tbn3d_branch2b\n",
      "layer_75:\tTrue\tactivation_21\n",
      "layer_76:\tTrue\tres3d_branch2c\n",
      "layer_77:\tTrue\tbn3d_branch2c\n",
      "layer_78:\tTrue\tadd_7\n",
      "layer_79:\tTrue\tactivation_22\n",
      "layer_80:\tTrue\tres4a_branch2a\n",
      "layer_81:\tTrue\tbn4a_branch2a\n",
      "layer_82:\tTrue\tactivation_23\n",
      "layer_83:\tTrue\tres4a_branch2b\n",
      "layer_84:\tTrue\tbn4a_branch2b\n",
      "layer_85:\tTrue\tactivation_24\n",
      "layer_86:\tTrue\tres4a_branch2c\n",
      "layer_87:\tTrue\tres4a_branch1\n",
      "layer_88:\tTrue\tbn4a_branch2c\n",
      "layer_89:\tTrue\tbn4a_branch1\n",
      "layer_90:\tTrue\tadd_8\n",
      "layer_91:\tTrue\tactivation_25\n",
      "layer_92:\tTrue\tres4b_branch2a\n",
      "layer_93:\tTrue\tbn4b_branch2a\n",
      "layer_94:\tTrue\tactivation_26\n",
      "layer_95:\tTrue\tres4b_branch2b\n",
      "layer_96:\tTrue\tbn4b_branch2b\n",
      "layer_97:\tTrue\tactivation_27\n",
      "layer_98:\tTrue\tres4b_branch2c\n",
      "layer_99:\tTrue\tbn4b_branch2c\n",
      "layer_100:\tTrue\tadd_9\n",
      "layer_101:\tTrue\tactivation_28\n",
      "layer_102:\tTrue\tres4c_branch2a\n",
      "layer_103:\tTrue\tbn4c_branch2a\n",
      "layer_104:\tTrue\tactivation_29\n",
      "layer_105:\tTrue\tres4c_branch2b\n",
      "layer_106:\tTrue\tbn4c_branch2b\n",
      "layer_107:\tTrue\tactivation_30\n",
      "layer_108:\tTrue\tres4c_branch2c\n",
      "layer_109:\tTrue\tbn4c_branch2c\n",
      "layer_110:\tTrue\tadd_10\n",
      "layer_111:\tTrue\tactivation_31\n",
      "layer_112:\tTrue\tres4d_branch2a\n",
      "layer_113:\tTrue\tbn4d_branch2a\n",
      "layer_114:\tTrue\tactivation_32\n",
      "layer_115:\tTrue\tres4d_branch2b\n",
      "layer_116:\tTrue\tbn4d_branch2b\n",
      "layer_117:\tTrue\tactivation_33\n",
      "layer_118:\tTrue\tres4d_branch2c\n",
      "layer_119:\tTrue\tbn4d_branch2c\n",
      "layer_120:\tTrue\tadd_11\n",
      "layer_121:\tTrue\tactivation_34\n",
      "layer_122:\tTrue\tres4e_branch2a\n",
      "layer_123:\tTrue\tbn4e_branch2a\n",
      "layer_124:\tTrue\tactivation_35\n",
      "layer_125:\tTrue\tres4e_branch2b\n",
      "layer_126:\tTrue\tbn4e_branch2b\n",
      "layer_127:\tTrue\tactivation_36\n",
      "layer_128:\tTrue\tres4e_branch2c\n",
      "layer_129:\tTrue\tbn4e_branch2c\n",
      "layer_130:\tTrue\tadd_12\n",
      "layer_131:\tTrue\tactivation_37\n",
      "layer_132:\tTrue\tres4f_branch2a\n",
      "layer_133:\tTrue\tbn4f_branch2a\n",
      "layer_134:\tTrue\tactivation_38\n",
      "layer_135:\tTrue\tres4f_branch2b\n",
      "layer_136:\tTrue\tbn4f_branch2b\n",
      "layer_137:\tTrue\tactivation_39\n",
      "layer_138:\tTrue\tres4f_branch2c\n",
      "layer_139:\tTrue\tbn4f_branch2c\n",
      "layer_140:\tTrue\tadd_13\n",
      "layer_141:\tTrue\tactivation_40\n",
      "layer_142:\tTrue\tres5a_branch2a\n",
      "layer_143:\tTrue\tbn5a_branch2a\n",
      "layer_144:\tTrue\tactivation_41\n",
      "layer_145:\tTrue\tres5a_branch2b\n",
      "layer_146:\tTrue\tbn5a_branch2b\n",
      "layer_147:\tTrue\tactivation_42\n",
      "layer_148:\tTrue\tres5a_branch2c\n",
      "layer_149:\tTrue\tres5a_branch1\n",
      "layer_150:\tTrue\tbn5a_branch2c\n",
      "layer_151:\tTrue\tbn5a_branch1\n",
      "layer_152:\tTrue\tadd_14\n",
      "layer_153:\tTrue\tactivation_43\n",
      "layer_154:\tTrue\tres5b_branch2a\n",
      "layer_155:\tTrue\tbn5b_branch2a\n",
      "layer_156:\tTrue\tactivation_44\n",
      "layer_157:\tTrue\tres5b_branch2b\n",
      "layer_158:\tTrue\tbn5b_branch2b\n",
      "layer_159:\tTrue\tactivation_45\n",
      "layer_160:\tTrue\tres5b_branch2c\n",
      "layer_161:\tTrue\tbn5b_branch2c\n",
      "layer_162:\tTrue\tadd_15\n",
      "layer_163:\tTrue\tactivation_46\n",
      "layer_164:\tTrue\tres5c_branch2a\n",
      "layer_165:\tTrue\tbn5c_branch2a\n",
      "layer_166:\tTrue\tactivation_47\n",
      "layer_167:\tTrue\tres5c_branch2b\n",
      "layer_168:\tTrue\tbn5c_branch2b\n",
      "layer_169:\tTrue\tactivation_48\n",
      "layer_170:\tTrue\tres5c_branch2c\n",
      "layer_171:\tTrue\tbn5c_branch2c\n",
      "layer_172:\tTrue\tadd_16\n",
      "layer_173:\tTrue\tactivation_49\n",
      "layer_174:\tTrue\tavg_pool\n"
     ]
    }
   ],
   "source": [
    "for i ,layer in enumerate(base_model.layers):\n",
    "    print(\"layer_{0}:\\t{1}\\t{2}\".format(i,layer.trainable, layer.name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "no fine-truning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#这个地方比较坑，调试比较费力，按照网上的操作,base_model.output的输出是tensor，以后都是tensor， 传递给其他层，切记，\n",
    "# TypeError: 'NoneType' object is not callable\n",
    "# 网上还将func 模型传给sequential（add）会出问题，#ValueError: Variable bn_conv1/moving_mean/biased already exists, disallowed.\n",
    "# Did you mean to set reuse=True in VarScope? Originally defined at:应该是版本问题，报错说变量存在，设置需要重用\n",
    "x=Flatten()(base_model.layers[172].output)#不必指定Input,或者base_model的output，就是最后一层\n",
    "# transfer_layer = model.get_layer('activation_48')\n",
    "# #获取权重tensor 切记和layer的区别,否则weights维度为none\n",
    "#【7,7,512】直接FC到3也不错，单独只polling操作也可\n",
    "# x=GlobalAveragePooling2D()(base_model.layers[172].output)\n",
    "x = Dropout(0.25)(x)\n",
    "x = Dense(3, activation='softmax')(x)\n",
    "model = Model(base_model.input, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/naruto/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:6: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras.pre..., epochs=10, validation_data=<keras.pre...)`\n",
      "  \n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "fit_generator() takes at least 3 arguments (4 given)",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-b7b0febad7fb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m# steps_per_epoch=10,  # nb_train_samples#每轮epoch遍历的samples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgenerator_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m#可自定义\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mnb_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;31m#,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;31m# verbose=1#,#控制显示方式，冗长\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m# validation_steps=530//64\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/naruto/anaconda2/lib/python2.7/site-packages/keras/legacy/interfaces.pyc\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     87\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 88\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_support_signature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetargspec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: fit_generator() takes at least 3 arguments (4 given)"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "history_ft = model.fit_generator(\n",
    "    generator_train,#可自定义\n",
    "    # samples_per_epoch=4170,  # nb_train_samples，Basically steps_per_epoch = samples_per_epoch/batch_size\n",
    "    # steps_per_epoch=10,  # nb_train_samples#每轮epoch遍历的samples\n",
    "    validation_data=generator_test,#可自定义\n",
    "    nb_epoch=10#,\n",
    "    # verbose=1#,#控制显示方式，冗长\n",
    "    # validation_steps=530//64\n",
    "    # workers=8\n",
    "    #use_multiprocessing=True,\n",
    "    # epochs=100\n",
    "    # nb_val_samples=530 # nb_val_samples`->`validation_steps\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fine-truning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer_0:\tFalse\tinput_1\n",
      "layer_1:\tFalse\tzero_padding2d_1\n",
      "layer_2:\tFalse\tconv1\n",
      "layer_3:\tFalse\tbn_conv1\n",
      "layer_4:\tFalse\tactivation_1\n",
      "layer_5:\tFalse\tmax_pooling2d_1\n",
      "layer_6:\tFalse\tres2a_branch2a\n",
      "layer_7:\tFalse\tbn2a_branch2a\n",
      "layer_8:\tFalse\tactivation_2\n",
      "layer_9:\tFalse\tres2a_branch2b\n",
      "layer_10:\tFalse\tbn2a_branch2b\n",
      "layer_11:\tFalse\tactivation_3\n",
      "layer_12:\tFalse\tres2a_branch2c\n",
      "layer_13:\tFalse\tres2a_branch1\n",
      "layer_14:\tFalse\tbn2a_branch2c\n",
      "layer_15:\tFalse\tbn2a_branch1\n",
      "layer_16:\tFalse\tadd_1\n",
      "layer_17:\tFalse\tactivation_4\n",
      "layer_18:\tFalse\tres2b_branch2a\n",
      "layer_19:\tFalse\tbn2b_branch2a\n",
      "layer_20:\tFalse\tactivation_5\n",
      "layer_21:\tFalse\tres2b_branch2b\n",
      "layer_22:\tFalse\tbn2b_branch2b\n",
      "layer_23:\tFalse\tactivation_6\n",
      "layer_24:\tFalse\tres2b_branch2c\n",
      "layer_25:\tFalse\tbn2b_branch2c\n",
      "layer_26:\tFalse\tadd_2\n",
      "layer_27:\tFalse\tactivation_7\n",
      "layer_28:\tFalse\tres2c_branch2a\n",
      "layer_29:\tFalse\tbn2c_branch2a\n",
      "layer_30:\tFalse\tactivation_8\n",
      "layer_31:\tFalse\tres2c_branch2b\n",
      "layer_32:\tFalse\tbn2c_branch2b\n",
      "layer_33:\tFalse\tactivation_9\n",
      "layer_34:\tFalse\tres2c_branch2c\n",
      "layer_35:\tFalse\tbn2c_branch2c\n",
      "layer_36:\tFalse\tadd_3\n",
      "layer_37:\tFalse\tactivation_10\n",
      "layer_38:\tFalse\tres3a_branch2a\n",
      "layer_39:\tFalse\tbn3a_branch2a\n",
      "layer_40:\tFalse\tactivation_11\n",
      "layer_41:\tFalse\tres3a_branch2b\n",
      "layer_42:\tFalse\tbn3a_branch2b\n",
      "layer_43:\tFalse\tactivation_12\n",
      "layer_44:\tFalse\tres3a_branch2c\n",
      "layer_45:\tFalse\tres3a_branch1\n",
      "layer_46:\tFalse\tbn3a_branch2c\n",
      "layer_47:\tFalse\tbn3a_branch1\n",
      "layer_48:\tFalse\tadd_4\n",
      "layer_49:\tFalse\tactivation_13\n",
      "layer_50:\tFalse\tres3b_branch2a\n",
      "layer_51:\tFalse\tbn3b_branch2a\n",
      "layer_52:\tFalse\tactivation_14\n",
      "layer_53:\tFalse\tres3b_branch2b\n",
      "layer_54:\tFalse\tbn3b_branch2b\n",
      "layer_55:\tFalse\tactivation_15\n",
      "layer_56:\tFalse\tres3b_branch2c\n",
      "layer_57:\tFalse\tbn3b_branch2c\n",
      "layer_58:\tFalse\tadd_5\n",
      "layer_59:\tFalse\tactivation_16\n",
      "layer_60:\tFalse\tres3c_branch2a\n",
      "layer_61:\tFalse\tbn3c_branch2a\n",
      "layer_62:\tFalse\tactivation_17\n",
      "layer_63:\tFalse\tres3c_branch2b\n",
      "layer_64:\tFalse\tbn3c_branch2b\n",
      "layer_65:\tFalse\tactivation_18\n",
      "layer_66:\tFalse\tres3c_branch2c\n",
      "layer_67:\tFalse\tbn3c_branch2c\n",
      "layer_68:\tFalse\tadd_6\n",
      "layer_69:\tFalse\tactivation_19\n",
      "layer_70:\tFalse\tres3d_branch2a\n",
      "layer_71:\tFalse\tbn3d_branch2a\n",
      "layer_72:\tFalse\tactivation_20\n",
      "layer_73:\tFalse\tres3d_branch2b\n",
      "layer_74:\tFalse\tbn3d_branch2b\n",
      "layer_75:\tFalse\tactivation_21\n",
      "layer_76:\tFalse\tres3d_branch2c\n",
      "layer_77:\tFalse\tbn3d_branch2c\n",
      "layer_78:\tFalse\tadd_7\n",
      "layer_79:\tFalse\tactivation_22\n",
      "layer_80:\tFalse\tres4a_branch2a\n",
      "layer_81:\tFalse\tbn4a_branch2a\n",
      "layer_82:\tFalse\tactivation_23\n",
      "layer_83:\tFalse\tres4a_branch2b\n",
      "layer_84:\tFalse\tbn4a_branch2b\n",
      "layer_85:\tFalse\tactivation_24\n",
      "layer_86:\tFalse\tres4a_branch2c\n",
      "layer_87:\tFalse\tres4a_branch1\n",
      "layer_88:\tFalse\tbn4a_branch2c\n",
      "layer_89:\tFalse\tbn4a_branch1\n",
      "layer_90:\tFalse\tadd_8\n",
      "layer_91:\tFalse\tactivation_25\n",
      "layer_92:\tFalse\tres4b_branch2a\n",
      "layer_93:\tFalse\tbn4b_branch2a\n",
      "layer_94:\tFalse\tactivation_26\n",
      "layer_95:\tFalse\tres4b_branch2b\n",
      "layer_96:\tFalse\tbn4b_branch2b\n",
      "layer_97:\tFalse\tactivation_27\n",
      "layer_98:\tFalse\tres4b_branch2c\n",
      "layer_99:\tFalse\tbn4b_branch2c\n",
      "layer_100:\tFalse\tadd_9\n",
      "layer_101:\tFalse\tactivation_28\n",
      "layer_102:\tFalse\tres4c_branch2a\n",
      "layer_103:\tFalse\tbn4c_branch2a\n",
      "layer_104:\tFalse\tactivation_29\n",
      "layer_105:\tFalse\tres4c_branch2b\n",
      "layer_106:\tFalse\tbn4c_branch2b\n",
      "layer_107:\tFalse\tactivation_30\n",
      "layer_108:\tFalse\tres4c_branch2c\n",
      "layer_109:\tFalse\tbn4c_branch2c\n",
      "layer_110:\tFalse\tadd_10\n",
      "layer_111:\tFalse\tactivation_31\n",
      "layer_112:\tFalse\tres4d_branch2a\n",
      "layer_113:\tFalse\tbn4d_branch2a\n",
      "layer_114:\tFalse\tactivation_32\n",
      "layer_115:\tFalse\tres4d_branch2b\n",
      "layer_116:\tFalse\tbn4d_branch2b\n",
      "layer_117:\tFalse\tactivation_33\n",
      "layer_118:\tFalse\tres4d_branch2c\n",
      "layer_119:\tFalse\tbn4d_branch2c\n",
      "layer_120:\tFalse\tadd_11\n",
      "layer_121:\tFalse\tactivation_34\n",
      "layer_122:\tFalse\tres4e_branch2a\n",
      "layer_123:\tFalse\tbn4e_branch2a\n",
      "layer_124:\tFalse\tactivation_35\n",
      "layer_125:\tFalse\tres4e_branch2b\n",
      "layer_126:\tFalse\tbn4e_branch2b\n",
      "layer_127:\tFalse\tactivation_36\n",
      "layer_128:\tFalse\tres4e_branch2c\n",
      "layer_129:\tFalse\tbn4e_branch2c\n",
      "layer_130:\tFalse\tadd_12\n",
      "layer_131:\tFalse\tactivation_37\n",
      "layer_132:\tFalse\tres4f_branch2a\n",
      "layer_133:\tFalse\tbn4f_branch2a\n",
      "layer_134:\tFalse\tactivation_38\n",
      "layer_135:\tFalse\tres4f_branch2b\n",
      "layer_136:\tFalse\tbn4f_branch2b\n",
      "layer_137:\tFalse\tactivation_39\n",
      "layer_138:\tFalse\tres4f_branch2c\n",
      "layer_139:\tFalse\tbn4f_branch2c\n",
      "layer_140:\tFalse\tadd_13\n",
      "layer_141:\tFalse\tactivation_40\n",
      "layer_142:\tFalse\tres5a_branch2a\n",
      "layer_143:\tFalse\tbn5a_branch2a\n",
      "layer_144:\tFalse\tactivation_41\n",
      "layer_145:\tFalse\tres5a_branch2b\n",
      "layer_146:\tFalse\tbn5a_branch2b\n",
      "layer_147:\tFalse\tactivation_42\n",
      "layer_148:\tFalse\tres5a_branch2c\n",
      "layer_149:\tFalse\tres5a_branch1\n",
      "layer_150:\tFalse\tbn5a_branch2c\n",
      "layer_151:\tFalse\tbn5a_branch1\n",
      "layer_152:\tFalse\tadd_14\n",
      "layer_153:\tFalse\tactivation_43\n",
      "layer_154:\tFalse\tres5b_branch2a\n",
      "layer_155:\tFalse\tbn5b_branch2a\n",
      "layer_156:\tFalse\tactivation_44\n",
      "layer_157:\tFalse\tres5b_branch2b\n",
      "layer_158:\tFalse\tbn5b_branch2b\n",
      "layer_159:\tFalse\tactivation_45\n",
      "layer_160:\tFalse\tres5b_branch2c\n",
      "layer_161:\tFalse\tbn5b_branch2c\n",
      "layer_162:\tFalse\tadd_15\n",
      "layer_163:\tFalse\tactivation_46\n",
      "layer_164:\tFalse\tres5c_branch2a\n",
      "layer_165:\tFalse\tbn5c_branch2a\n",
      "layer_166:\tFalse\tactivation_47\n",
      "layer_167:\tFalse\tres5c_branch2b\n",
      "layer_168:\tFalse\tbn5c_branch2b\n",
      "layer_169:\tFalse\tactivation_48\n",
      "layer_170:\tFalse\tres5c_branch2c\n",
      "layer_171:\tFalse\tbn5c_branch2c\n",
      "layer_172:\tTrue\tadd_16\n",
      "layer_173:\tTrue\tactivation_49\n",
      "layer_174:\tTrue\tavg_pool\n"
     ]
    }
   ],
   "source": [
    "for layer in base_model.layers[:172]:\n",
    "   layer.trainable = False\n",
    "for layer in base_model.layers[172:]:\n",
    "   layer.trainable = True\n",
    "# model.summary()\n",
    "for i ,layer in enumerate(base_model.layers):\n",
    "    print(\"layer_{0}:\\t{1}\\t{2}\".format(i,layer.trainable, layer.name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看到最后三层可ｔｒａｉｎａｂｌｅ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/naruto/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:14: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras.pre..., verbose=1, workers=8, validation_data=<keras.pre..., epochs=10, validation_steps=8)`\n",
      "  \n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "fit_generator() takes at least 3 arguments (7 given)",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-b3d917a3a8ad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m#控制显示方式，冗长\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m530\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0;31m# use_multiprocessing=True,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;31m# epochs=100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/naruto/anaconda2/lib/python2.7/site-packages/keras/legacy/interfaces.pyc\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     87\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 88\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_support_signature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetargspec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: fit_generator() takes at least 3 arguments (7 given)"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "model.compile(optimizer='adadelta',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# 节省内存，类似tf的queue\n",
    "history_ft = model.fit_generator(\n",
    "    generator_train,#可自定义\n",
    "    # samples_per_epoch=4170,  # nb_train_samples，Basically steps_per_epoch = samples_per_epoch/batch_size\n",
    "    # steps_per_epoch=10,  # nb_train_samples#每轮epoch遍历的samples\n",
    "    validation_data=generator_test,#可自定义\n",
    "    nb_epoch=10,\n",
    "    verbose=1,#控制显示方式，冗长\n",
    "    validation_steps=530//64,\n",
    "    workers=8,\n",
    "    # use_multiprocessing=True,\n",
    "    # epochs=100\n",
    "    # nb_val_samples=530 # nb_val_samples`->`validation_steps\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
