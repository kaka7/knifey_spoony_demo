{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "19397ff1-c191-43ef-8924-f643d9ef6460"
    }
   },
   "source": [
    "transfer learning with keras"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "nbpresent": {
     "id": "d7c1d2ff-413f-4b4b-b243-d98edcfc67e4"
    }
   },
   "source": [
    "## encoding=utf-8\n",
    "# 从某一层开始获取权重并开始transferlearning\n",
    "# 输入图像的大小建议和pre_process model要求的输入大小一致，效果会更好\n",
    "# 从处理方式的灵活性上推荐函数式模型，sequential只是特例\n",
    "# 各层的激活函数优先选sigmoid ，即便是最后一层的softmax?\n",
    "# 将最后一层的输出作为输入的ＴＬ实验３ 起始准确率不到２０　而本实验直接将池化层的结果作为输入　然后ｓｏｆｔｍａｘｘ获得的起始准确率达６０％\n",
    "\n",
    "#总结一下：　ｔransfer learning :利用现有的模型，将特征层剥离，然后fine-truning\n",
    "# １可以直接将输出层作为输入\n",
    "# ２将中间某层（最好是特征层，比如卷积后，ＦＣ已经到达了抽象的感知事物的理解程度）或多层（trainable）\n",
    "# 另外，还有就是自己写将多次结果的数据写到ｈ５文件中，然后读取\n",
    "\n",
    "# keras 2.1.5\n",
    "# 报错：StopIteration: unsupported operand type(s) for /=: 'JpegImageFile' and 'float'\n",
    "# 降级到2.1.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "nbpresent": {
     "id": "f2208191-de63-49db-b651-3ef35e3ab1d1"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.applications import *\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "#释放显存\n",
    "os.system(\"nvidia-smi | grep vpython3 | awk '{print $3}' | xargs kill -9\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "ed3ef879-9acf-4df2-886d-79211cde7712"
    }
   },
   "outputs": [],
   "source": [
    "height=224\n",
    "train_batch_size=64\n",
    "test_batch_size=64\n",
    "FLAG = None\n",
    "#assert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "nbpresent": {
     "id": "30d1b856-de54-4089-a373-291dae812efe"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4170 images belonging to 3 classes.\n",
      "Found 530 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "train_data_dir='/home/naruto/PycharmProjects/knifey_spoony_demo/data/knifey-spoony/train_data_link/'\n",
    "test_data_dir='/home/naruto/PycharmProjects/knifey_spoony_demo/data/knifey-spoony/test/'\n",
    "gen = ImageDataGenerator()\n",
    "generator_train = gen.flow_from_directory(train_data_dir, target_size=(height, height),batch_size=train_batch_size)\n",
    "generator_test = gen.flow_from_directory(test_data_dir, target_size=(height, height),batch_size=test_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "nbpresent": {
     "id": "93201c43-d3ee-4301-824d-570f4008f7b8"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 112, 112, 64) 9472        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bn_conv1 (BatchNormalization)   (None, 112, 112, 64) 256         conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 112, 112, 64) 0           bn_conv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 55, 55, 64)   0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2a (Conv2D)         (None, 55, 55, 64)   4160        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2a (BatchNormalizati (None, 55, 55, 64)   256         res2a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 55, 55, 64)   0           bn2a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2b (Conv2D)         (None, 55, 55, 64)   36928       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2b (BatchNormalizati (None, 55, 55, 64)   256         res2a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 55, 55, 64)   0           bn2a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2c (Conv2D)         (None, 55, 55, 256)  16640       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch1 (Conv2D)          (None, 55, 55, 256)  16640       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2c (BatchNormalizati (None, 55, 55, 256)  1024        res2a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch1 (BatchNormalizatio (None, 55, 55, 256)  1024        res2a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 55, 55, 256)  0           bn2a_branch2c[0][0]              \n",
      "                                                                 bn2a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 55, 55, 256)  0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2a (Conv2D)         (None, 55, 55, 64)   16448       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2a (BatchNormalizati (None, 55, 55, 64)   256         res2b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 55, 55, 64)   0           bn2b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2b (Conv2D)         (None, 55, 55, 64)   36928       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2b (BatchNormalizati (None, 55, 55, 64)   256         res2b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 55, 55, 64)   0           bn2b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2c (Conv2D)         (None, 55, 55, 256)  16640       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2c (BatchNormalizati (None, 55, 55, 256)  1024        res2b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 55, 55, 256)  0           bn2b_branch2c[0][0]              \n",
      "                                                                 activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 55, 55, 256)  0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2a (Conv2D)         (None, 55, 55, 64)   16448       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2a (BatchNormalizati (None, 55, 55, 64)   256         res2c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 55, 55, 64)   0           bn2c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2b (Conv2D)         (None, 55, 55, 64)   36928       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2b (BatchNormalizati (None, 55, 55, 64)   256         res2c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 55, 55, 64)   0           bn2c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2c (Conv2D)         (None, 55, 55, 256)  16640       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2c (BatchNormalizati (None, 55, 55, 256)  1024        res2c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 55, 55, 256)  0           bn2c_branch2c[0][0]              \n",
      "                                                                 activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 55, 55, 256)  0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2a (Conv2D)         (None, 28, 28, 128)  32896       activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 28, 28, 128)  0           bn3a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 28, 28, 128)  0           bn3a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch1 (Conv2D)          (None, 28, 28, 512)  131584      activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch1 (BatchNormalizatio (None, 28, 28, 512)  2048        res3a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 28, 28, 512)  0           bn3a_branch2c[0][0]              \n",
      "                                                                 bn3a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 28, 28, 512)  0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 28, 28, 128)  0           bn3b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 28, 28, 128)  0           bn3b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 28, 28, 512)  0           bn3b_branch2c[0][0]              \n",
      "                                                                 activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 28, 28, 512)  0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 28, 28, 128)  0           bn3c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 28, 28, 128)  0           bn3c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 28, 28, 512)  0           bn3c_branch2c[0][0]              \n",
      "                                                                 activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 28, 28, 512)  0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 28, 28, 128)  0           bn3d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 28, 28, 128)  0           bn3d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 28, 28, 512)  0           bn3d_branch2c[0][0]              \n",
      "                                                                 activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 28, 28, 512)  0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2a (Conv2D)         (None, 14, 14, 256)  131328      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 14, 14, 256)  0           bn4a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 14, 14, 256)  0           bn4a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch1 (Conv2D)          (None, 14, 14, 1024) 525312      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch1 (BatchNormalizatio (None, 14, 14, 1024) 4096        res4a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 14, 14, 1024) 0           bn4a_branch2c[0][0]              \n",
      "                                                                 bn4a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 14, 14, 1024) 0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 14, 14, 256)  0           bn4b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 14, 14, 256)  0           bn4b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 14, 14, 1024) 0           bn4b_branch2c[0][0]              \n",
      "                                                                 activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 14, 14, 1024) 0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 14, 14, 256)  0           bn4c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 14, 14, 256)  0           bn4c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 14, 14, 1024) 0           bn4c_branch2c[0][0]              \n",
      "                                                                 activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 14, 14, 1024) 0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 14, 14, 256)  0           bn4d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 14, 14, 256)  0           bn4d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 14, 14, 1024) 0           bn4d_branch2c[0][0]              \n",
      "                                                                 activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 14, 14, 1024) 0           add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 14, 14, 256)  0           bn4e_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 14, 14, 256)  0           bn4e_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4e_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 14, 14, 1024) 0           bn4e_branch2c[0][0]              \n",
      "                                                                 activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 14, 14, 1024) 0           add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 14, 14, 256)  0           bn4f_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 14, 14, 256)  0           bn4f_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4f_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 14, 14, 1024) 0           bn4f_branch2c[0][0]              \n",
      "                                                                 activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 14, 14, 1024) 0           add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2a (Conv2D)         (None, 7, 7, 512)    524800      activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 7, 7, 512)    0           bn5a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 7, 7, 512)    0           bn5a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch1 (Conv2D)          (None, 7, 7, 2048)   2099200     activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch1 (BatchNormalizatio (None, 7, 7, 2048)   8192        res5a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 7, 7, 2048)   0           bn5a_branch2c[0][0]              \n",
      "                                                                 bn5a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 7, 7, 2048)   0           add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 7, 7, 512)    0           bn5b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 7, 7, 512)    0           bn5b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 7, 7, 2048)   0           bn5b_branch2c[0][0]              \n",
      "                                                                 activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 7, 7, 2048)   0           add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 7, 7, 512)    0           bn5c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 7, 7, 512)    0           bn5c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_16 (Add)                    (None, 7, 7, 2048)   0           bn5c_branch2c[0][0]              \n",
      "                                                                 activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 7, 7, 2048)   0           add_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "avg_pool (AveragePooling2D)     (None, 1, 1, 2048)   0           activation_49[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 23,587,712\n",
      "Trainable params: 23,534,592\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# base_model = VGG16(include_top=True, weights='imagenet')需要下载，速度慢，\n",
    "# include_top=true时下载也比较慢，需要测试等于true时的模型结构\n",
    "# input_tensor=Input((height, height, 3))报错ValueError: The shape of the input to \"Flatten\" is not fully defined (got (None, None, 2048).\n",
    "#  Make sure to pass a complete \"input_shape\" or \"batch_input_shape\" argument to the first layer in your model.，是因为此时用的Ｍｏｄｅｌ需要预先指定ｉｎｐｕｔ\n",
    "base_model = ResNet50(input_tensor=Input((height, height, 3)),weights='imagenet', include_top=False)\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "nbpresent": {
     "id": "2d8b3b1f-6974-4094-9a9d-d840a7b0cdf6"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer_0:\tFalse\tinput_1\n",
      "layer_1:\tTrue\tconv1\n",
      "layer_2:\tTrue\tbn_conv1\n",
      "layer_3:\tTrue\tactivation_1\n",
      "layer_4:\tTrue\tmax_pooling2d_1\n",
      "layer_5:\tTrue\tres2a_branch2a\n",
      "layer_6:\tTrue\tbn2a_branch2a\n",
      "layer_7:\tTrue\tactivation_2\n",
      "layer_8:\tTrue\tres2a_branch2b\n",
      "layer_9:\tTrue\tbn2a_branch2b\n",
      "layer_10:\tTrue\tactivation_3\n",
      "layer_11:\tTrue\tres2a_branch2c\n",
      "layer_12:\tTrue\tres2a_branch1\n",
      "layer_13:\tTrue\tbn2a_branch2c\n",
      "layer_14:\tTrue\tbn2a_branch1\n",
      "layer_15:\tTrue\tadd_1\n",
      "layer_16:\tTrue\tactivation_4\n",
      "layer_17:\tTrue\tres2b_branch2a\n",
      "layer_18:\tTrue\tbn2b_branch2a\n",
      "layer_19:\tTrue\tactivation_5\n",
      "layer_20:\tTrue\tres2b_branch2b\n",
      "layer_21:\tTrue\tbn2b_branch2b\n",
      "layer_22:\tTrue\tactivation_6\n",
      "layer_23:\tTrue\tres2b_branch2c\n",
      "layer_24:\tTrue\tbn2b_branch2c\n",
      "layer_25:\tTrue\tadd_2\n",
      "layer_26:\tTrue\tactivation_7\n",
      "layer_27:\tTrue\tres2c_branch2a\n",
      "layer_28:\tTrue\tbn2c_branch2a\n",
      "layer_29:\tTrue\tactivation_8\n",
      "layer_30:\tTrue\tres2c_branch2b\n",
      "layer_31:\tTrue\tbn2c_branch2b\n",
      "layer_32:\tTrue\tactivation_9\n",
      "layer_33:\tTrue\tres2c_branch2c\n",
      "layer_34:\tTrue\tbn2c_branch2c\n",
      "layer_35:\tTrue\tadd_3\n",
      "layer_36:\tTrue\tactivation_10\n",
      "layer_37:\tTrue\tres3a_branch2a\n",
      "layer_38:\tTrue\tbn3a_branch2a\n",
      "layer_39:\tTrue\tactivation_11\n",
      "layer_40:\tTrue\tres3a_branch2b\n",
      "layer_41:\tTrue\tbn3a_branch2b\n",
      "layer_42:\tTrue\tactivation_12\n",
      "layer_43:\tTrue\tres3a_branch2c\n",
      "layer_44:\tTrue\tres3a_branch1\n",
      "layer_45:\tTrue\tbn3a_branch2c\n",
      "layer_46:\tTrue\tbn3a_branch1\n",
      "layer_47:\tTrue\tadd_4\n",
      "layer_48:\tTrue\tactivation_13\n",
      "layer_49:\tTrue\tres3b_branch2a\n",
      "layer_50:\tTrue\tbn3b_branch2a\n",
      "layer_51:\tTrue\tactivation_14\n",
      "layer_52:\tTrue\tres3b_branch2b\n",
      "layer_53:\tTrue\tbn3b_branch2b\n",
      "layer_54:\tTrue\tactivation_15\n",
      "layer_55:\tTrue\tres3b_branch2c\n",
      "layer_56:\tTrue\tbn3b_branch2c\n",
      "layer_57:\tTrue\tadd_5\n",
      "layer_58:\tTrue\tactivation_16\n",
      "layer_59:\tTrue\tres3c_branch2a\n",
      "layer_60:\tTrue\tbn3c_branch2a\n",
      "layer_61:\tTrue\tactivation_17\n",
      "layer_62:\tTrue\tres3c_branch2b\n",
      "layer_63:\tTrue\tbn3c_branch2b\n",
      "layer_64:\tTrue\tactivation_18\n",
      "layer_65:\tTrue\tres3c_branch2c\n",
      "layer_66:\tTrue\tbn3c_branch2c\n",
      "layer_67:\tTrue\tadd_6\n",
      "layer_68:\tTrue\tactivation_19\n",
      "layer_69:\tTrue\tres3d_branch2a\n",
      "layer_70:\tTrue\tbn3d_branch2a\n",
      "layer_71:\tTrue\tactivation_20\n",
      "layer_72:\tTrue\tres3d_branch2b\n",
      "layer_73:\tTrue\tbn3d_branch2b\n",
      "layer_74:\tTrue\tactivation_21\n",
      "layer_75:\tTrue\tres3d_branch2c\n",
      "layer_76:\tTrue\tbn3d_branch2c\n",
      "layer_77:\tTrue\tadd_7\n",
      "layer_78:\tTrue\tactivation_22\n",
      "layer_79:\tTrue\tres4a_branch2a\n",
      "layer_80:\tTrue\tbn4a_branch2a\n",
      "layer_81:\tTrue\tactivation_23\n",
      "layer_82:\tTrue\tres4a_branch2b\n",
      "layer_83:\tTrue\tbn4a_branch2b\n",
      "layer_84:\tTrue\tactivation_24\n",
      "layer_85:\tTrue\tres4a_branch2c\n",
      "layer_86:\tTrue\tres4a_branch1\n",
      "layer_87:\tTrue\tbn4a_branch2c\n",
      "layer_88:\tTrue\tbn4a_branch1\n",
      "layer_89:\tTrue\tadd_8\n",
      "layer_90:\tTrue\tactivation_25\n",
      "layer_91:\tTrue\tres4b_branch2a\n",
      "layer_92:\tTrue\tbn4b_branch2a\n",
      "layer_93:\tTrue\tactivation_26\n",
      "layer_94:\tTrue\tres4b_branch2b\n",
      "layer_95:\tTrue\tbn4b_branch2b\n",
      "layer_96:\tTrue\tactivation_27\n",
      "layer_97:\tTrue\tres4b_branch2c\n",
      "layer_98:\tTrue\tbn4b_branch2c\n",
      "layer_99:\tTrue\tadd_9\n",
      "layer_100:\tTrue\tactivation_28\n",
      "layer_101:\tTrue\tres4c_branch2a\n",
      "layer_102:\tTrue\tbn4c_branch2a\n",
      "layer_103:\tTrue\tactivation_29\n",
      "layer_104:\tTrue\tres4c_branch2b\n",
      "layer_105:\tTrue\tbn4c_branch2b\n",
      "layer_106:\tTrue\tactivation_30\n",
      "layer_107:\tTrue\tres4c_branch2c\n",
      "layer_108:\tTrue\tbn4c_branch2c\n",
      "layer_109:\tTrue\tadd_10\n",
      "layer_110:\tTrue\tactivation_31\n",
      "layer_111:\tTrue\tres4d_branch2a\n",
      "layer_112:\tTrue\tbn4d_branch2a\n",
      "layer_113:\tTrue\tactivation_32\n",
      "layer_114:\tTrue\tres4d_branch2b\n",
      "layer_115:\tTrue\tbn4d_branch2b\n",
      "layer_116:\tTrue\tactivation_33\n",
      "layer_117:\tTrue\tres4d_branch2c\n",
      "layer_118:\tTrue\tbn4d_branch2c\n",
      "layer_119:\tTrue\tadd_11\n",
      "layer_120:\tTrue\tactivation_34\n",
      "layer_121:\tTrue\tres4e_branch2a\n",
      "layer_122:\tTrue\tbn4e_branch2a\n",
      "layer_123:\tTrue\tactivation_35\n",
      "layer_124:\tTrue\tres4e_branch2b\n",
      "layer_125:\tTrue\tbn4e_branch2b\n",
      "layer_126:\tTrue\tactivation_36\n",
      "layer_127:\tTrue\tres4e_branch2c\n",
      "layer_128:\tTrue\tbn4e_branch2c\n",
      "layer_129:\tTrue\tadd_12\n",
      "layer_130:\tTrue\tactivation_37\n",
      "layer_131:\tTrue\tres4f_branch2a\n",
      "layer_132:\tTrue\tbn4f_branch2a\n",
      "layer_133:\tTrue\tactivation_38\n",
      "layer_134:\tTrue\tres4f_branch2b\n",
      "layer_135:\tTrue\tbn4f_branch2b\n",
      "layer_136:\tTrue\tactivation_39\n",
      "layer_137:\tTrue\tres4f_branch2c\n",
      "layer_138:\tTrue\tbn4f_branch2c\n",
      "layer_139:\tTrue\tadd_13\n",
      "layer_140:\tTrue\tactivation_40\n",
      "layer_141:\tTrue\tres5a_branch2a\n",
      "layer_142:\tTrue\tbn5a_branch2a\n",
      "layer_143:\tTrue\tactivation_41\n",
      "layer_144:\tTrue\tres5a_branch2b\n",
      "layer_145:\tTrue\tbn5a_branch2b\n",
      "layer_146:\tTrue\tactivation_42\n",
      "layer_147:\tTrue\tres5a_branch2c\n",
      "layer_148:\tTrue\tres5a_branch1\n",
      "layer_149:\tTrue\tbn5a_branch2c\n",
      "layer_150:\tTrue\tbn5a_branch1\n",
      "layer_151:\tTrue\tadd_14\n",
      "layer_152:\tTrue\tactivation_43\n",
      "layer_153:\tTrue\tres5b_branch2a\n",
      "layer_154:\tTrue\tbn5b_branch2a\n",
      "layer_155:\tTrue\tactivation_44\n",
      "layer_156:\tTrue\tres5b_branch2b\n",
      "layer_157:\tTrue\tbn5b_branch2b\n",
      "layer_158:\tTrue\tactivation_45\n",
      "layer_159:\tTrue\tres5b_branch2c\n",
      "layer_160:\tTrue\tbn5b_branch2c\n",
      "layer_161:\tTrue\tadd_15\n",
      "layer_162:\tTrue\tactivation_46\n",
      "layer_163:\tTrue\tres5c_branch2a\n",
      "layer_164:\tTrue\tbn5c_branch2a\n",
      "layer_165:\tTrue\tactivation_47\n",
      "layer_166:\tTrue\tres5c_branch2b\n",
      "layer_167:\tTrue\tbn5c_branch2b\n",
      "layer_168:\tTrue\tactivation_48\n",
      "layer_169:\tTrue\tres5c_branch2c\n",
      "layer_170:\tTrue\tbn5c_branch2c\n",
      "layer_171:\tTrue\tadd_16\n",
      "layer_172:\tTrue\tactivation_49\n",
      "layer_173:\tTrue\tavg_pool\n"
     ]
    }
   ],
   "source": [
    "for i ,layer in enumerate(base_model.layers):\n",
    "    print(\"layer_{0}:\\t{1}\\t{2}\".format(i,layer.trainable, layer.name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "3e638d29-1cc4-4637-a8ca-5375ee54a53d"
    }
   },
   "source": [
    "no fine-truning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "cdb34603-6f8f-4de0-9ead-2e2ae23d35f7"
    }
   },
   "outputs": [],
   "source": [
    "#这个地方比较坑，调试比较费力，按照网上的操作,base_model.output的输出是tensor，以后都是tensor， 传递给其他层，切记，\n",
    "# TypeError: 'NoneType' object is not callable\n",
    "# 网上还将func 模型传给sequential（add）会出问题，#ValueError: Variable bn_conv1/moving_mean/biased already exists, disallowed.\n",
    "# Did you mean to set reuse=True in VarScope? Originally defined at:应该是版本问题，报错说变量存在，设置需要重用\n",
    "x=Flatten()(base_model.layers[172].output)#不必指定Input,或者base_model的output，就是最后一层\n",
    "# transfer_layer = model.get_layer('activation_48')\n",
    "# #获取权重tensor 切记和layer的区别,否则weights维度为none\n",
    "#【7,7,512】直接FC到3也不错，单独只polling操作也可\n",
    "# x=GlobalAveragePooling2D()(base_model.layers[172].output)\n",
    "x = Dropout(0.25)(x)\n",
    "x = Dense(3, activation='softmax')(x)\n",
    "model = Model(base_model.input, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "3b2d88a9-c1bd-4c32-9bb3-f7c0e7d53942"
    }
   },
   "outputs": [],
   "source": [
    "# ＃这里不是ｆａｌｓｅ那么就是整个网络重新训练易导致ＯＯＭ\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "#\n",
    "# # compile the model (should be done *after* setting layers to non-trainable)\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "nbpresent": {
     "id": "9f7ea1e8-5ed3-43e8-9f03-6716f8ae8c80"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:9: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "  if __name__ == '__main__':\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:9: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras.pre..., verbose=1, epochs=10, validation_data=<keras.pre..., workers=8, validation_steps=8)`\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "66/66 [==============================] - 57s 857ms/step - loss: 5.3328 - acc: 0.6400 - val_loss: 6.5979 - val_acc: 0.5176\n",
      "Epoch 2/10\n",
      "66/66 [==============================] - 54s 812ms/step - loss: 3.6860 - acc: 0.7579 - val_loss: 3.4095 - val_acc: 0.7039\n",
      "Epoch 3/10\n",
      "66/66 [==============================] - 53s 802ms/step - loss: 0.7251 - acc: 0.9324 - val_loss: 4.5239 - val_acc: 0.6652\n",
      "Epoch 4/10\n",
      "66/66 [==============================] - 53s 802ms/step - loss: 0.3257 - acc: 0.9713 - val_loss: 5.5997 - val_acc: 0.6094\n",
      "Epoch 5/10\n",
      "66/66 [==============================] - 54s 812ms/step - loss: 0.2487 - acc: 0.9792 - val_loss: 5.6345 - val_acc: 0.6030\n",
      "Epoch 6/10\n",
      "66/66 [==============================] - 53s 810ms/step - loss: 0.1166 - acc: 0.9881 - val_loss: 5.4358 - val_acc: 0.6330\n",
      "Epoch 7/10\n",
      "66/66 [==============================] - 53s 809ms/step - loss: 0.1335 - acc: 0.9884 - val_loss: 4.9898 - val_acc: 0.6330\n",
      "Epoch 8/10\n",
      "66/66 [==============================] - 53s 806ms/step - loss: 0.1093 - acc: 0.9898 - val_loss: 6.3404 - val_acc: 0.5644\n",
      "Epoch 9/10\n",
      "66/66 [==============================] - 53s 805ms/step - loss: 0.0939 - acc: 0.9910 - val_loss: 6.8915 - val_acc: 0.5343\n",
      "Epoch 10/10\n",
      "66/66 [==============================] - 54s 817ms/step - loss: 0.0789 - acc: 0.9927 - val_loss: 5.6018 - val_acc: 0.6250\n"
     ]
    }
   ],
   "source": [
    "history_ft = model.fit_generator(\n",
    "    generator_train,#可自定义\n",
    "    # samples_per_epoch=4170,  # nb_train_samples，Basically steps_per_epoch = samples_per_epoch/batch_size\n",
    "    # steps_per_epoch=10,  # nb_train_samples#每轮epoch遍历的samples\n",
    "    validation_data=generator_test,#可自定义\n",
    "    nb_epoch=10,\n",
    "    verbose=1,#控制显示方式，冗长\n",
    "    validation_steps=530//64,\n",
    "    workers=8,\n",
    "    # use_multiprocessing=True,\n",
    "    # epochs=100\n",
    "    # nb_val_samples=530 # nb_val_samples`->`validation_steps\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "fine-truning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer_0:\tFalse\tinput_1\n",
      "layer_1:\tFalse\tconv1\n",
      "layer_2:\tFalse\tbn_conv1\n",
      "layer_3:\tFalse\tactivation_1\n",
      "layer_4:\tFalse\tmax_pooling2d_1\n",
      "layer_5:\tFalse\tres2a_branch2a\n",
      "layer_6:\tFalse\tbn2a_branch2a\n",
      "layer_7:\tFalse\tactivation_2\n",
      "layer_8:\tFalse\tres2a_branch2b\n",
      "layer_9:\tFalse\tbn2a_branch2b\n",
      "layer_10:\tFalse\tactivation_3\n",
      "layer_11:\tFalse\tres2a_branch2c\n",
      "layer_12:\tFalse\tres2a_branch1\n",
      "layer_13:\tFalse\tbn2a_branch2c\n",
      "layer_14:\tFalse\tbn2a_branch1\n",
      "layer_15:\tFalse\tadd_1\n",
      "layer_16:\tFalse\tactivation_4\n",
      "layer_17:\tFalse\tres2b_branch2a\n",
      "layer_18:\tFalse\tbn2b_branch2a\n",
      "layer_19:\tFalse\tactivation_5\n",
      "layer_20:\tFalse\tres2b_branch2b\n",
      "layer_21:\tFalse\tbn2b_branch2b\n",
      "layer_22:\tFalse\tactivation_6\n",
      "layer_23:\tFalse\tres2b_branch2c\n",
      "layer_24:\tFalse\tbn2b_branch2c\n",
      "layer_25:\tFalse\tadd_2\n",
      "layer_26:\tFalse\tactivation_7\n",
      "layer_27:\tFalse\tres2c_branch2a\n",
      "layer_28:\tFalse\tbn2c_branch2a\n",
      "layer_29:\tFalse\tactivation_8\n",
      "layer_30:\tFalse\tres2c_branch2b\n",
      "layer_31:\tFalse\tbn2c_branch2b\n",
      "layer_32:\tFalse\tactivation_9\n",
      "layer_33:\tFalse\tres2c_branch2c\n",
      "layer_34:\tFalse\tbn2c_branch2c\n",
      "layer_35:\tFalse\tadd_3\n",
      "layer_36:\tFalse\tactivation_10\n",
      "layer_37:\tFalse\tres3a_branch2a\n",
      "layer_38:\tFalse\tbn3a_branch2a\n",
      "layer_39:\tFalse\tactivation_11\n",
      "layer_40:\tFalse\tres3a_branch2b\n",
      "layer_41:\tFalse\tbn3a_branch2b\n",
      "layer_42:\tFalse\tactivation_12\n",
      "layer_43:\tFalse\tres3a_branch2c\n",
      "layer_44:\tFalse\tres3a_branch1\n",
      "layer_45:\tFalse\tbn3a_branch2c\n",
      "layer_46:\tFalse\tbn3a_branch1\n",
      "layer_47:\tFalse\tadd_4\n",
      "layer_48:\tFalse\tactivation_13\n",
      "layer_49:\tFalse\tres3b_branch2a\n",
      "layer_50:\tFalse\tbn3b_branch2a\n",
      "layer_51:\tFalse\tactivation_14\n",
      "layer_52:\tFalse\tres3b_branch2b\n",
      "layer_53:\tFalse\tbn3b_branch2b\n",
      "layer_54:\tFalse\tactivation_15\n",
      "layer_55:\tFalse\tres3b_branch2c\n",
      "layer_56:\tFalse\tbn3b_branch2c\n",
      "layer_57:\tFalse\tadd_5\n",
      "layer_58:\tFalse\tactivation_16\n",
      "layer_59:\tFalse\tres3c_branch2a\n",
      "layer_60:\tFalse\tbn3c_branch2a\n",
      "layer_61:\tFalse\tactivation_17\n",
      "layer_62:\tFalse\tres3c_branch2b\n",
      "layer_63:\tFalse\tbn3c_branch2b\n",
      "layer_64:\tFalse\tactivation_18\n",
      "layer_65:\tFalse\tres3c_branch2c\n",
      "layer_66:\tFalse\tbn3c_branch2c\n",
      "layer_67:\tFalse\tadd_6\n",
      "layer_68:\tFalse\tactivation_19\n",
      "layer_69:\tFalse\tres3d_branch2a\n",
      "layer_70:\tFalse\tbn3d_branch2a\n",
      "layer_71:\tFalse\tactivation_20\n",
      "layer_72:\tFalse\tres3d_branch2b\n",
      "layer_73:\tFalse\tbn3d_branch2b\n",
      "layer_74:\tFalse\tactivation_21\n",
      "layer_75:\tFalse\tres3d_branch2c\n",
      "layer_76:\tFalse\tbn3d_branch2c\n",
      "layer_77:\tFalse\tadd_7\n",
      "layer_78:\tFalse\tactivation_22\n",
      "layer_79:\tFalse\tres4a_branch2a\n",
      "layer_80:\tFalse\tbn4a_branch2a\n",
      "layer_81:\tFalse\tactivation_23\n",
      "layer_82:\tFalse\tres4a_branch2b\n",
      "layer_83:\tFalse\tbn4a_branch2b\n",
      "layer_84:\tFalse\tactivation_24\n",
      "layer_85:\tFalse\tres4a_branch2c\n",
      "layer_86:\tFalse\tres4a_branch1\n",
      "layer_87:\tFalse\tbn4a_branch2c\n",
      "layer_88:\tFalse\tbn4a_branch1\n",
      "layer_89:\tFalse\tadd_8\n",
      "layer_90:\tFalse\tactivation_25\n",
      "layer_91:\tFalse\tres4b_branch2a\n",
      "layer_92:\tFalse\tbn4b_branch2a\n",
      "layer_93:\tFalse\tactivation_26\n",
      "layer_94:\tFalse\tres4b_branch2b\n",
      "layer_95:\tFalse\tbn4b_branch2b\n",
      "layer_96:\tFalse\tactivation_27\n",
      "layer_97:\tFalse\tres4b_branch2c\n",
      "layer_98:\tFalse\tbn4b_branch2c\n",
      "layer_99:\tFalse\tadd_9\n",
      "layer_100:\tFalse\tactivation_28\n",
      "layer_101:\tFalse\tres4c_branch2a\n",
      "layer_102:\tFalse\tbn4c_branch2a\n",
      "layer_103:\tFalse\tactivation_29\n",
      "layer_104:\tFalse\tres4c_branch2b\n",
      "layer_105:\tFalse\tbn4c_branch2b\n",
      "layer_106:\tFalse\tactivation_30\n",
      "layer_107:\tFalse\tres4c_branch2c\n",
      "layer_108:\tFalse\tbn4c_branch2c\n",
      "layer_109:\tFalse\tadd_10\n",
      "layer_110:\tFalse\tactivation_31\n",
      "layer_111:\tFalse\tres4d_branch2a\n",
      "layer_112:\tFalse\tbn4d_branch2a\n",
      "layer_113:\tFalse\tactivation_32\n",
      "layer_114:\tFalse\tres4d_branch2b\n",
      "layer_115:\tFalse\tbn4d_branch2b\n",
      "layer_116:\tFalse\tactivation_33\n",
      "layer_117:\tFalse\tres4d_branch2c\n",
      "layer_118:\tFalse\tbn4d_branch2c\n",
      "layer_119:\tFalse\tadd_11\n",
      "layer_120:\tFalse\tactivation_34\n",
      "layer_121:\tFalse\tres4e_branch2a\n",
      "layer_122:\tFalse\tbn4e_branch2a\n",
      "layer_123:\tFalse\tactivation_35\n",
      "layer_124:\tFalse\tres4e_branch2b\n",
      "layer_125:\tFalse\tbn4e_branch2b\n",
      "layer_126:\tFalse\tactivation_36\n",
      "layer_127:\tFalse\tres4e_branch2c\n",
      "layer_128:\tFalse\tbn4e_branch2c\n",
      "layer_129:\tFalse\tadd_12\n",
      "layer_130:\tFalse\tactivation_37\n",
      "layer_131:\tFalse\tres4f_branch2a\n",
      "layer_132:\tFalse\tbn4f_branch2a\n",
      "layer_133:\tFalse\tactivation_38\n",
      "layer_134:\tFalse\tres4f_branch2b\n",
      "layer_135:\tFalse\tbn4f_branch2b\n",
      "layer_136:\tFalse\tactivation_39\n",
      "layer_137:\tFalse\tres4f_branch2c\n",
      "layer_138:\tFalse\tbn4f_branch2c\n",
      "layer_139:\tFalse\tadd_13\n",
      "layer_140:\tFalse\tactivation_40\n",
      "layer_141:\tFalse\tres5a_branch2a\n",
      "layer_142:\tFalse\tbn5a_branch2a\n",
      "layer_143:\tFalse\tactivation_41\n",
      "layer_144:\tFalse\tres5a_branch2b\n",
      "layer_145:\tFalse\tbn5a_branch2b\n",
      "layer_146:\tFalse\tactivation_42\n",
      "layer_147:\tFalse\tres5a_branch2c\n",
      "layer_148:\tFalse\tres5a_branch1\n",
      "layer_149:\tFalse\tbn5a_branch2c\n",
      "layer_150:\tFalse\tbn5a_branch1\n",
      "layer_151:\tFalse\tadd_14\n",
      "layer_152:\tFalse\tactivation_43\n",
      "layer_153:\tFalse\tres5b_branch2a\n",
      "layer_154:\tFalse\tbn5b_branch2a\n",
      "layer_155:\tFalse\tactivation_44\n",
      "layer_156:\tFalse\tres5b_branch2b\n",
      "layer_157:\tFalse\tbn5b_branch2b\n",
      "layer_158:\tFalse\tactivation_45\n",
      "layer_159:\tFalse\tres5b_branch2c\n",
      "layer_160:\tFalse\tbn5b_branch2c\n",
      "layer_161:\tFalse\tadd_15\n",
      "layer_162:\tFalse\tactivation_46\n",
      "layer_163:\tFalse\tres5c_branch2a\n",
      "layer_164:\tFalse\tbn5c_branch2a\n",
      "layer_165:\tFalse\tactivation_47\n",
      "layer_166:\tFalse\tres5c_branch2b\n",
      "layer_167:\tFalse\tbn5c_branch2b\n",
      "layer_168:\tFalse\tactivation_48\n",
      "layer_169:\tFalse\tres5c_branch2c\n",
      "layer_170:\tFalse\tbn5c_branch2c\n",
      "layer_171:\tFalse\tadd_16\n",
      "layer_172:\tTrue\tactivation_49\n",
      "layer_173:\tTrue\tavg_pool\n"
     ]
    }
   ],
   "source": [
    "for layer in base_model.layers[:172]:\n",
    "   layer.trainable = False\n",
    "for layer in base_model.layers[172:]:\n",
    "   layer.trainable = True\n",
    "for i ,layer in enumerate(base_model.layers):\n",
    "    print(\"layer_{0}:\\t{1}\\t{2}\".format(i,layer.trainable, layer.name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:14: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "  \n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:14: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras.pre..., verbose=1, epochs=10, validation_data=<keras.pre..., workers=8, validation_steps=8)`\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "66/66 [==============================] - 54s 826ms/step - loss: 0.0196 - acc: 0.9981 - val_loss: 4.1522 - val_acc: 0.7044\n",
      "Epoch 2/10\n",
      "66/66 [==============================] - 53s 810ms/step - loss: 0.0160 - acc: 0.9979 - val_loss: 4.5040 - val_acc: 0.6853\n",
      "Epoch 3/10\n",
      "66/66 [==============================] - 53s 806ms/step - loss: 0.0299 - acc: 0.9974 - val_loss: 3.7857 - val_acc: 0.7268\n",
      "Epoch 4/10\n",
      "66/66 [==============================] - 53s 810ms/step - loss: 0.0220 - acc: 0.9983 - val_loss: 4.1234 - val_acc: 0.6967\n",
      "Epoch 5/10\n",
      "66/66 [==============================] - 53s 808ms/step - loss: 0.0109 - acc: 0.9992 - val_loss: 3.5250 - val_acc: 0.7468\n",
      "Epoch 6/10\n",
      "66/66 [==============================] - 53s 810ms/step - loss: 0.0101 - acc: 0.9994 - val_loss: 3.5465 - val_acc: 0.7525\n",
      "Epoch 7/10\n",
      "66/66 [==============================] - 53s 810ms/step - loss: 0.0110 - acc: 0.9991 - val_loss: 3.8087 - val_acc: 0.7253\n",
      "Epoch 8/10\n",
      "66/66 [==============================] - 53s 808ms/step - loss: 0.0143 - acc: 0.9986 - val_loss: 3.5571 - val_acc: 0.7411\n",
      "Epoch 9/10\n",
      "66/66 [==============================] - 53s 807ms/step - loss: 0.0086 - acc: 0.9994 - val_loss: 3.5798 - val_acc: 0.7368\n",
      "Epoch 10/10\n",
      "66/66 [==============================] - 54s 820ms/step - loss: 0.0098 - acc: 0.9991 - val_loss: 3.0679 - val_acc: 0.7786\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adadelta',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# 节省内存，类似tf的queue\n",
    "history_ft = model.fit_generator(\n",
    "    generator_train,#可自定义\n",
    "    # samples_per_epoch=4170,  # nb_train_samples，Basically steps_per_epoch = samples_per_epoch/batch_size\n",
    "    # steps_per_epoch=10,  # nb_train_samples#每轮epoch遍历的samples\n",
    "    validation_data=generator_test,#可自定义\n",
    "    nb_epoch=10,\n",
    "    verbose=1,#控制显示方式，冗长\n",
    "    validation_steps=530//64,\n",
    "    workers=8,\n",
    "    # use_multiprocessing=True,\n",
    "    # epochs=100\n",
    "    # nb_val_samples=530 # nb_val_samples`->`validation_steps\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里直接将特征层ｆｌａｔｔｅｎ　然后ｄｅｎｓｅ，效果明显好于前者"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python (vpython3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
